{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np \n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt, ceil\n",
    "from timeit import default_timer as timer\n",
    "import keras.layers as layers\n",
    "from keras import Model, Input\n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D,\\\n",
    "    MaxPool2D, AvgPool2D, Reshape,\\\n",
    "    LSTM, MaxPooling2D,TimeDistributed\n",
    "# from tensorflow.keras.layers import  BatchNormalization, MaxPool2D, MaxPooling2D, TimeDistributed\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "# import tensorflow.keras\n",
    "import random\n",
    "keras.backend.clear_session()\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize List to Append each data file\n",
    "data=[]\n",
    "DATA_PATH = '/datasets/home/21/321/ee228sp20ta1/G36/'\n",
    "#'Different Data Files' for training,  validation adn test\n",
    "filenames=['processed_data.pickle']\n",
    "# i=0\n",
    "def show_data(data, num_exp):\n",
    "    '''\n",
    "    Display some random instances\n",
    "    of input data.\n",
    "    \n",
    "    Input:-\n",
    "    -----\n",
    "    data :  type(4-D array)\n",
    "        Input data in the form\n",
    "        of images\n",
    "        \n",
    "    '''\n",
    "    assert 0<=num_exp<=5\n",
    "\n",
    "    x=[np.array([i]) for i in np.arange(data.shape[0])]\n",
    "    rnd_ind = random.choices(x, k = num_exp)\n",
    "    images = (data[rnd_ind,:,:,:]).squeeze(1)\n",
    "    h_stack_image =np.hstack(images) # Getting Incorrect Images and Stacking\n",
    "                                 # them to print in one go\n",
    "    plt.figure(figsize = (30,6))\n",
    "    plt.imshow(h_stack_image, cmap='gray')    # Converting into unsigned integers for plt.imshow              \n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "        \n",
    "#Read each data file from filesname\n",
    "for i,fil in enumerate(filenames):\n",
    "    #Read Path of the directory of datafiles\n",
    "    #Use readbyte to read the data\n",
    "    \n",
    "    file= os.path.join(DATA_PATH, fil)\n",
    "    with open(file, 'rb') as f:\n",
    "        d = pickle.load(f, encoding='latin1')  \n",
    "        #Append currect data file to data <List>\n",
    "        data.append(d)\n",
    "   \n",
    "        # Converting labels of data into one-hot vector\n",
    "        data[i]['y_train'] = to_categorical(data[i]['y_train'], num_classes=43)\n",
    "        data[i]['y_val'] = to_categorical(data[i]['y_val'], num_classes=43)\n",
    "        data[i]['y_test'] = to_categorical(data[i]['y_test'], num_classes=43)\n",
    "        \n",
    "        \n",
    "        #normalization and transpose to make number of channels at the end\n",
    "\n",
    "        data[i]['x_train'] = (data[i]['x_train'])\n",
    "        data[i]['x_val'] = (data[i]['x_val'])\n",
    "        data[i]['x_test'] = (data[i]['x_test'])\n",
    "        print('data', i)\n",
    "        \n",
    "        show_data(data[i]['x_train'], 5)\n",
    "        # Showing shape of each data pickle (uncomment if needed)\n",
    "        '''\n",
    "        for k, j in data[i].items():\n",
    "                if k == 'labels':\n",
    "                   print(k + ':', len(j))\n",
    "                else: \n",
    "                   print(k + ':', j.shape)\n",
    "        print(i)\n",
    "        '''\n",
    "        # Show some random images of each data pickle (uncomment if needed)\n",
    "        \n",
    "#         i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "\n",
    "class Model():\n",
    "    '''\n",
    "    Class\n",
    "       Variables:-\n",
    "       ---------\n",
    "       self.input_dim : type(int)\n",
    "           Number of channels of input\n",
    "           image of the data e.g rgb image\n",
    "           has input_dim =3\n",
    "\n",
    "       self.model : type(keras model)\n",
    "           Its flexible to be changed\n",
    "\n",
    "        self.model_name : type(str)\n",
    "            Type of model to be implemented\n",
    "    '''\n",
    "    def __init__(self, input_dim, model_name):\n",
    "\n",
    "        assert input_dim==1 or input_dim==3\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.model_name = model_name\n",
    "\n",
    "        #Model Implementation        \n",
    "        if(model_name==\"AlexNet\"):\n",
    "            self.model = tf.keras.Sequential([\n",
    "                         tf.keras.layers.Conv2D(64, 1, activation='relu', input_shape=(32,32,input_dim)),\n",
    "                         tf.keras.layers.Conv2D(128, 3, activation='relu'),\n",
    "                         tf.keras.layers.MaxPool2D(padding = 'same',strides=2),\n",
    "                         tf.keras.layers.Conv2D(128, 5, activation='relu',padding=\"same\"),\n",
    "                         tf.keras.layers.MaxPool2D(padding = 'same',strides=2),\n",
    "                         tf.keras.layers.Flatten(),\n",
    "                         tf.keras.layers.Dense(300, activation='relu'),\n",
    "                         tf.keras.layers.Dense(43, activation='softmax')\n",
    "                    ])\n",
    "            \n",
    "        elif(model_name == \"RNN\" ):\n",
    "            batch_size = 64\n",
    "            row_hidden = 128\n",
    "            col_hidden = 128\n",
    "            num_classes = 43\n",
    "            row, col, pixel = 32,32,3\n",
    "            \n",
    "            x = Input(shape=(row, col, pixel))\n",
    "            encoded_rows = TimeDistributed(LSTM(row_hidden))(x)\n",
    "            encoded_columns = LSTM(col_hidden)(encoded_rows)\n",
    "            prediction = Dense(num_classes, activation='softmax')(encoded_columns)\n",
    "            model = keras.Model(x, prediction)\n",
    "            \n",
    "            self.model = model\n",
    "        \n",
    "    def compile_model(self, learn_rate = 0.001, initial_learning_rate = 0.0001,decay_steps=80000, decay_rate=1):\n",
    "        '''\n",
    "        Compiles user defined model\n",
    "        based on input parameters.\n",
    "        It also provides the option \n",
    "        of learning rate decay by\n",
    "        specifying initial_learning_rate,\n",
    "        decay_steps, decay_rate=1.\n",
    "        It uses Adam optimization \n",
    "        and Categorical Cross Entropy Loss \n",
    "        Function but can be changed.\n",
    "\n",
    "        Input:-\n",
    "        -----\n",
    "        learn_rate: type(float) \n",
    "            It defines learning rate\n",
    "            of the optimizer\n",
    "\n",
    "         initial_learning_rate :type(float)\n",
    "            It defines initial learning\n",
    "            rate of the optimizer if user\n",
    "            wants to set exponential decay\n",
    "\n",
    "        decay_steps: type(number)\n",
    "            It defines number of decay \n",
    "            steps of the learning rate\n",
    "            scheduler\n",
    "\n",
    "        '''\n",
    "        \n",
    "#         initial_learning_rate = 0.0001\n",
    "        lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "                      initial_learning_rate,\n",
    "                      decay_steps=decay_steps,\n",
    "                      decay_rate=decay_rate,\n",
    "                      staircase=True)\n",
    "        \n",
    "        self.model.compile(optimizer=keras.optimizers.Adam(learning_rate=learn_rate),\n",
    "                           loss=keras.losses.CategoricalCrossentropy(),\n",
    "                            metrics=['accuracy'])\n",
    "    \n",
    "    def train_model(self, x_train, y_train, x_val, y_val, epoch = 5,  batch_sz= 128, shuffle=False):\n",
    "        '''\n",
    "        Trains user defined model \n",
    "        based on input parameters.\n",
    "        \n",
    "        Input:-\n",
    "        -----\n",
    "        x_train :  type(4-D array)\n",
    "            Input training data in\n",
    "            the form of images\n",
    "        y_train :  type(2-D array)\n",
    "            Labels of input training \n",
    "            data in the form of one\n",
    "            hot encoding vectors\n",
    "        x_val :  type(3-D array)\n",
    "            Input validation data in\n",
    "            the form of images\n",
    "        y_val :  type(2-D array)\n",
    "            Labels of input validation\n",
    "            data data in the form of one\n",
    "            hot encoding vectors\n",
    "        epoch: type(int)\n",
    "            Number of epochs for training\n",
    "        batch_sz: type(int) \n",
    "            Batch size for training of data\n",
    "        shuffle : type(bool)\n",
    "            If true, it tells the\n",
    "            model to shuffle input data\n",
    "            before training. Opposite\n",
    "            is true shuffle is false\n",
    "            \n",
    "        Output:\n",
    "        ------\n",
    "            Returns trained model\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        return self.model.fit(x_train,y_train,validation_data = (x_val,y_val),\n",
    "                   batch_size=batch_sz,epochs=epoch, verbose=1, shuffle=shuffle, initial_epoch=0)\n",
    "    \n",
    "    \n",
    "    def evaluate_model(self, x_test, y_test):\n",
    "        '''\n",
    "        Evaluate prediction accuracy \n",
    "        and loss value of the trained \n",
    "        model onto test data.\n",
    "        \n",
    "        Input:-\n",
    "        -----\n",
    "        x_test :  type(4-D array)\n",
    "            Input test data in the\n",
    "            form of images.\n",
    "        y_test :  type(2-D array)\n",
    "            Labels of input test data\n",
    "            in the form of one hot\n",
    "            encoding vectors.\n",
    "       \n",
    "    \n",
    "        Output:-\n",
    "        ------\n",
    "        Returns prediction accuracy \n",
    "        and loss value of the trained \n",
    "        model onto test data.\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        return self.model.evaluate(x_test, y_test, verbose = 2)\n",
    "    \n",
    "    def predict_label(self, x_test):\n",
    "        '''\n",
    "        Returns labels of input test\n",
    "        data in the form of one hot\n",
    "        encoding vectors.\n",
    "\n",
    "        Input:\n",
    "        x_test :  type(4-D array) \n",
    "            Input test data in the form of images\n",
    "    \n",
    "        Output:\n",
    "        ------\n",
    "        Returns a type(2-D array)\n",
    "        predicted labels of input\n",
    "        test data in the form of\n",
    "        one hot encoding vectors\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        return self.model.predict(x_test)\n",
    "    \n",
    "    \n",
    "    def show_incorrect_examples(self, y_predict, x_test, y_test, num_exp):\n",
    "        '''  \n",
    "        Show num_exp number of incorrectly\n",
    "        predicted examples by the trained\n",
    "        model and print corresponding ground\n",
    "        truth and model alongside.\n",
    "\n",
    "        Input:-\n",
    "        -----\n",
    "        x_test :  type(3-D array) \n",
    "        Input test data in the form of images\n",
    "\n",
    "        y_test :  type(2-D array)\n",
    "         Labels of input test data in the\n",
    "         form of one hot encoding vectors\n",
    "\n",
    "        y_predict : type(2-D array)\n",
    "         Predicted labels of input test \n",
    "         data in the form of one hot encoding vectors\n",
    "\n",
    "        num_exp: type (int)\n",
    "         Defines the number of incorrect\n",
    "         examples to display its value\n",
    "         must be less than 6 and positive\n",
    "        '''\n",
    "        assert 0<=num_exp<=5\n",
    "        \n",
    "        y_predict_id = np.argmax(y_predict, axis=1)    #Collecting true category from one hot encoding vector\n",
    "        y_test_id = np.argmax(y_test, axis =1)         #Collecting true category from one hot encoding vector\n",
    "\n",
    "        image_data = x_test\n",
    "        false_preds_ind = np.argwhere(y_predict_id!=y_test_id)  #Indices where prediction is incorrect\n",
    "\n",
    "        rnd_ind = random.choices(false_preds_ind, k = num_exp)\n",
    "        print(rnd_ind) \n",
    "\n",
    "        false_pred_images = (image_data[rnd_ind,:,:,:]).squeeze(1)\n",
    "\n",
    "        h_stack_image     =np.hstack(false_pred_images) #Getting Incorrect Images and Stacking\n",
    "                                                                                       # them to print in one go\n",
    "\n",
    "        plt.figure(figsize = (30,6))\n",
    "\n",
    "        plt.imshow(h_stack_image.astype('uint8'), cmap='gray')    # Converting into unsigned integers for plt.imshow              \n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "\n",
    "        print('Ground_Truth ', y_test_id[np.ravel(rnd_ind)])  #Printing the true categories\n",
    "        print('Prediction ', y_predict_id[np.ravel(rnd_ind)])\n",
    "        \n",
    "    def show_correct_examples(self, y_predict,x_test, y_test, num_exp):\n",
    "        '''  \n",
    "        Show num_exp number of correctly\n",
    "        predicted examples by the trained\n",
    "        model and print corresponding \n",
    "        ground truth and model alongside.\n",
    "\n",
    "        Input:-\n",
    "        -----\n",
    "        x_test :  type(3-D array) \n",
    "         Input test data in the form of images\n",
    "\n",
    "        y_test :  type(2-D array)\n",
    "         Labels of input test data in\n",
    "         the form of one hot encoding vectors\n",
    "\n",
    "        y_predict : type(2-D array)\n",
    "         Predicted labels of input test\n",
    "         data in the form of one hot encoding vectors\n",
    "\n",
    "        num_exp: type (int)\n",
    "         It defines the number of correct\n",
    "         examples to display its value\n",
    "         must be less than 6 and positive\n",
    "        '''\n",
    "        assert num_exp<=5\n",
    "        \n",
    "        #Collecting true category from one hot encoding vector\n",
    "        y_predict_id =   np.argmax(y_predict, axis=1)             \n",
    "\n",
    "        #Collecting true category from one hot encoding vector   \n",
    "        y_test_id    =   np.argmax(y_test, axis =1)         \n",
    "        image_data   =   x_test\n",
    "\n",
    "\n",
    "        #Indices where prediction is correct \n",
    "        corr_preds_ind=       np.argwhere(y_predict_id==y_test_id)  \n",
    "        rnd_ind        =       random.choices(corr_preds_ind, k = num_exp)\n",
    "\n",
    "        corr_pred_images = (image_data[rnd_ind,:,:,:]).squeeze(1)\n",
    "        #Getting correct Images and Stacking them to print in one go \n",
    "        h_stack_image     =np.hstack(corr_pred_images) \n",
    "\n",
    "\n",
    "        plt.figure(figsize = (30,6))\n",
    "\n",
    "        plt.imshow(h_stack_image.astype('uint8'), cmap='gray')    # Converting into unsigned integers for plt.imshow              \n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        print('Ground_Truth ', y_test_id[np.ravel(rnd_ind)])  #Printing the true categories\n",
    "        print('Prediction ', y_predict_id[np.ravel(rnd_ind)])   #Printing the predicted categories\n",
    "    \n",
    "    def save(self, filename):\n",
    "        '''\n",
    "        Save the currect state of the\n",
    "        model into file specified by\n",
    "        the name as filename and delete\n",
    "        that model to decrease load memory.\n",
    "        \n",
    "        Input:-\n",
    "        -----\n",
    "        filename: type(string)\n",
    "            Specify name of the file in\n",
    "            which you wnat to store\n",
    "            the state of the model\n",
    "        '''\n",
    "        assert(isinstance(filename,str))\n",
    "        \n",
    "        self.model.save(filename)\n",
    "        del self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correct_img= 5\n",
    "incorrect_img = 5\n",
    "\n",
    "# Set the model to be used\n",
    "model_name = 'RNN'\n",
    "\n",
    "#Define the name of file in which you want to store train acc, val, acc_loss, val_loss line by line fr each data pickle\n",
    "result_file='model_'+model_name+'.csv'\n",
    "#Make sure you remove such file if it alread exists\n",
    "'''os.remove(result_file)\n",
    "'''\n",
    "epoch=150\n",
    "\n",
    "for k in range(0,1):\n",
    "    input_dim = data[k]['x_train'].shape[3]\n",
    "    xtrain =data[k]['x_train']\n",
    "    ytrain=data[k]['y_train']\n",
    "    xval= data[k]['x_val'] \n",
    "    yval= data[k]['y_val'] \n",
    "    xtest=data[k]['x_test'] \n",
    "    ytest=data[k]['y_test'] \n",
    "    #Define a new model instance  \n",
    "    model_instance=Model(input_dim,model_name)\n",
    "    #Comiple the model\n",
    "    model_instance.compile_model()\n",
    "\n",
    "    #Train the model\n",
    "    fit_history=model_instance.train_model(xtrain, ytrain, xval, yval, epoch=epoch)\n",
    "\n",
    "    #Evaluate the model\n",
    "    predict = model_instance.evaluate_model(xtest,ytest)\n",
    "\n",
    "    # predicted labels  \n",
    "    pred_label= model_instance.predict_label(xtest)\n",
    "\n",
    "\n",
    "    #Create a new file and start saving data \n",
    "    pd.DataFrame.from_dict(fit_history.history).to_csv(result_file)\n",
    "\n",
    "    #Display incorrectly classified examples\n",
    "    model_instance.show_incorrect_examples(pred_label,xtest,ytest, correct_img)\n",
    "\n",
    "    #Display correctly classified examples      \n",
    "    model_instance.show_correct_examples(pred_label,xtest,ytest, incorrect_img)  \n",
    "    #defines file name to save the model state  \n",
    "    model_filename='model_'+model_name+'_data'\n",
    "\n",
    "    model_instance.save(model_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Dsiplay Accuracy plot, loss plot for training data as well as validation data\n",
    "#Defines the name of file from which data is to bread\n",
    "result_file='model_'+model_name+'.csv'\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "y = pd.read_csv(result_file)\n",
    "for i in range(0,1):\n",
    "    plt.subplot(2,2,1)\n",
    "\n",
    "    #Plot training accuracy and validation accuracy\n",
    "    plt.plot(np.arange(1,epoch+1), y['accuracy'], marker='*', label = 'tra_acc for data'+ str(i))\n",
    "\n",
    "    plt.title('Training Accuracy Plot')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2,2,2)\n",
    "    plt.plot(np.arange(1,epoch+1), y['val_accuracy'], marker='*', label = 'val_acc for data'+ str(i))  \n",
    "    plt.title('Validation Accuracy Plot')\n",
    "    plt.legend()\n",
    "\n",
    "    #Plot training loss and validation loss\n",
    "    plt.subplot(2,2,3)\n",
    "    plt.plot(np.arange(1,epoch+1), y['loss'], marker= '*', label = 'loss for data'+ str(i))  \n",
    "    plt.title('Training Loss Plot')\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "    plt.subplot(2,2,4)\n",
    "    plt.plot(np.arange(1,epoch+1), y['val_loss'], marker= '*',label = 'val_oss for data'+ str(i)) \n",
    "    plt.title('Validation Loss Plot')\n",
    "    plt.legend()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
